# Uber_ETL_Pipeline

## Introduction

The goal of this project is to develop an ETL pipeline to process and analyze Uber data, utilizing GCP services such as GCP Storage, Compute Instance, and BigQuery. The pipeline will extract, transform, and load the data into a structured database in GCP for efficient querying and visualization using tools like Python, Mage Data Pipeline Tool, and Looker Studio
## Architecture 
<img src="architecture.jpg">

## Technology Used
- Programming Language - Python

Google Cloud Platform
1. Google Storage
2. Compute Instance 
3. BigQuery
4. Looker Studio



## Dataset Used
TLC Trip Record Data
Yellow and green taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. 

Here is the dataset used - [https://github.com/darshilparmar/uber-etl-pipeline-data-engineering-project/blob/main/data/uber_data.csv](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

